{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# this cell creates a set of files used by the examples below. On readthedocs, this cell is hidden.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import xarray as xr\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# time vector on 4 years\n",
    "times = pd.date_range('2000-01-01', '2003-12-31', freq='D')\n",
    "# temperature data as seasonal cycle -18 to 18\n",
    "tas = xr.DataArray(-18 * np.cos(2 * np.pi * times.dayofyear / 365),\n",
    "                   dims=('time',), coords={'time': times}, name ='tas',\n",
    "                   attrs={'units': 'degC', 'standard_name': 'air_temperature', \n",
    "                          'long_name': 'Mean air temperature at surface'})\n",
    "\n",
    "# write 10 members adding cubic-smoothed gaussian noise of wavenumber 43 and amplitude 20\n",
    "# resulting temp will oscillate between -18 and 38\n",
    "for i in range(10):\n",
    "    tasi = tas + 20 * interp1d(np.arange(43), np.random.random((43,)), kind='quadratic')(np.linspace(0, 42, tas.size))\n",
    "    tasi.name = 'tas'\n",
    "    tasi.attrs.update(tas.attrs)\n",
    "    tasi.attrs['title'] = f'tas of member {i:02d}'\n",
    "    tasi.to_netcdf(f'ens_tas_m{i}.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensembles\n",
    "=========\n",
    "\n",
    "An important aspect of climate models is that they are run multiple times with some initial perturbations to see how they replicate the natural variability of the climate. Through [xclim.ensembles](../api.rst#module-xclim.ensembles), xclim provides an easy interface to compute ensemble statistics on different members. Once again, like in [xclim.subset](../api.rst#module-xclim.subset), most methods perform checks and conversion on top of simpler `xarray` methods, providing an easier interface to use.\n",
    "\n",
    "### create_ensemble\n",
    "Our first step is to create an ensemble. This methods takes a list of files defining the same variables over the same coordinates and concatenates them into one dataset with an added dimension `realization`.\n",
    "\n",
    "Using `xarray` a very simple way of creating an ensemble dataset would be :\n",
    "```python\n",
    "open_mfdataset(files, concat_dim='realization') \n",
    "```\n",
    "\n",
    "However, this is only successful when the dimensions of all the files are identical AND only if the calendar type of each netcdf file is the same\n",
    "\n",
    "xclim's `create_ensemble()` method overcomes these constraints selecting the common time period to all files and assigns a standard calendar type to the dataset. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Input netcdf files still require equal spatial dimension size (e.g. lon, lat dimensions). <br>\n",
    "If input data contains multiple cftime calendar types they must not be at daily frequency.\n",
    "\n",
    "</div>\n",
    "\n",
    "Given files all named `ens_tas_m[member number].nc`, we use `glob` to get a list of all those files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import xclim as xc\n",
    "import xarray as xr\n",
    "# Set display to HTML sytle (for fancy output)\n",
    "xr.set_options(display_style='html', display_width=50)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from xclim import ensembles\n",
    "\n",
    "ens = ensembles.create_ensemble(glob.glob('ens_tas_m*.nc')).load()\n",
    "ens.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-dark')\n",
    "plt.rcParams['figure.figsize'] = (13, 5)\n",
    "ens.tas.plot(hue='realization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens.tas  # Attributes of the first dataset to be opened are copied to the final output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble statistics\n",
    "Beyond creating ensemble dataset the `xclim.ensembles` module contains functions for calculating statistics between realizations\n",
    "\n",
    "**Ensemble mean, standard-deviation, max & min**\n",
    "\n",
    "In the example below we use xclim's `ensemble_mean_std_max_min()` to calculate statistics across the 10 realizations in our test dataset. Output variables are created combining the original variable name `tas` with addtional ending indicating the statistic calculated on the realization dimension : `_mean`, `_stdev`, `_min`, `_max`\n",
    "\n",
    "The resulting output now contains 4 derived variables from the original single variable in our ensemble dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_stats = ensembles.ensemble_mean_std_max_min(ens)\n",
    "ens_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble percentiles\n",
    "\n",
    "Here we use xclim's `ensemble_percentiles()` to calculate percentile values across the 10 realizations. \n",
    "Output variables are created for combining the original variable name `tas` with the addtional ending `_p{x}` where x are the input percentile values `default = [10, 50, 90]`. Compared to numpy's `percentile()` and xarray's `quantile()`, this method handles more efficiently dataset with invalid values and the chunking along the realization dimension (which is automatic when dask arrays are used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_perc = ensembles.ensemble_percentiles(ens, values=[15, 50, 85])\n",
    "ens_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.fill_between(ens_stats.time.values, ens_stats.tas_min, ens_stats.tas_max, alpha=0.3, label='Min-Max')\n",
    "ax.fill_between(ens_perc.time.values, ens_perc.tas_p15, ens_perc.tas_p85, alpha=0.5, label='Perc. 15-85')\n",
    "ax._get_lines.get_next_color()  # Hack to get different line\n",
    "ax._get_lines.get_next_color()\n",
    "ax.plot(ens_stats.time.values, ens_stats.tas_mean, linewidth=2, label='Mean')\n",
    "ax.plot(ens_perc.time.values, ens_perc.tas_p50, linewidth=2, label='Median')\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
