{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# This cell is not visible when the documentation is built.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import xarray as xr\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# time vector on 4 years\n",
    "times = pd.date_range(\"2000-01-01\", \"2003-12-31\", freq=\"D\")\n",
    "# temperature data as seasonal cycle -18 to 18\n",
    "tas = xr.DataArray(\n",
    "    -18 * np.cos(2 * np.pi * times.dayofyear / 365),\n",
    "    dims=(\"time\",),\n",
    "    coords={\"time\": times},\n",
    "    name=\"tas\",\n",
    "    attrs={\n",
    "        \"units\": \"degC\",\n",
    "        \"standard_name\": \"air_temperature\",\n",
    "        \"long_name\": \"Mean air temperature at surface\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# write 10 members adding cubic-smoothed gaussian noise of wavenumber 43 and amplitude 20\n",
    "# resulting temp will oscillate between -18 and 38\n",
    "for i in range(10):\n",
    "    tasi = tas + 20 * interp1d(\n",
    "        np.arange(43), np.random.random((43,)), kind=\"quadratic\"\n",
    "    )(np.linspace(0, 42, tas.size))\n",
    "    tasi.name = \"tas\"\n",
    "    tasi.attrs.update(tas.attrs)\n",
    "    tasi.attrs[\"title\"] = f\"tas of member {i:02d}\"\n",
    "    tasi.to_netcdf(f\"ens_tas_m{i}.nc\")\n",
    "\n",
    "# Create 'toy' criteria selection data\n",
    "np.random.normal(loc=3.5, scale=1.5, size=50)\n",
    "# crit['delta_annual_tavg']\n",
    "np.random.seed(0)\n",
    "test = xr.DataArray(\n",
    "    np.random.normal(loc=3, scale=1.5, size=100), dims=[\"realization\"]\n",
    ").assign_coords(horizon=\"2041-2070\")\n",
    "test = xr.concat(\n",
    "    (\n",
    "        test,\n",
    "        xr.DataArray(\n",
    "            np.random.normal(loc=5.34, scale=2, size=100), dims=[\"realization\"]\n",
    "        ).assign_coords(horizon=\"2071-2100\"),\n",
    "    ),\n",
    "    dim=\"horizon\",\n",
    ")\n",
    "\n",
    "ds_crit = xr.Dataset()\n",
    "\n",
    "ds_crit[\"delta_annual_tavg\"] = test\n",
    "test = xr.DataArray(\n",
    "    np.random.normal(loc=5, scale=5, size=100), dims=[\"realization\"]\n",
    ").assign_coords(horizon=\"2041-2070\")\n",
    "test = xr.concat(\n",
    "    (\n",
    "        test,\n",
    "        xr.DataArray(\n",
    "            np.random.normal(loc=10, scale=8, size=100), dims=[\"realization\"]\n",
    "        ).assign_coords(horizon=\"2071-2100\"),\n",
    "    ),\n",
    "    dim=\"horizon\",\n",
    ")\n",
    "ds_crit[\"delta_annual_prtot\"] = test\n",
    "test = xr.DataArray(\n",
    "    np.random.normal(loc=0, scale=3, size=100), dims=[\"realization\"]\n",
    ").assign_coords(horizon=\"2041-2070\")\n",
    "test = xr.concat(\n",
    "    (\n",
    "        test,\n",
    "        xr.DataArray(\n",
    "            np.random.normal(loc=2, scale=4, size=100), dims=[\"realization\"]\n",
    "        ).assign_coords(horizon=\"2071-2100\"),\n",
    "    ),\n",
    "    dim=\"horizon\",\n",
    ")\n",
    "ds_crit[\"delta_JJA_prtot\"] = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensembles\n",
    "=========\n",
    "\n",
    "An important aspect of climate models is that they are run multiple times with some initial perturbations to see how they replicate the natural variability of the climate. Through [xclim.ensembles](../api.rst#ensembles-module), xclim provides an easy interface to compute ensemble statistics on different members. Most methods perform checks and conversion on top of simpler `xarray` methods, providing an easier interface to use.\n",
    "\n",
    "### create_ensemble\n",
    "Our first step is to create an ensemble. This method takes a list of files defining the same variables over the same coordinates and concatenates them into one dataset with an added dimension `realization`.\n",
    "\n",
    "Using `xarray` a very simple way of creating an ensemble dataset would be :\n",
    "```python\n",
    "import xarray\n",
    "\n",
    "xarray.open_mfdataset(files, concat_dim='realization')\n",
    "```\n",
    "\n",
    "However, this is only successful when the dimensions of all the files are identical AND only if the calendar type of each netcdf file is the same\n",
    "\n",
    "xclim's `create_ensemble()` method overcomes these constraints, selecting the common time period to all files and assigns a standard calendar type to the dataset.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Input netcdf files still require equal spatial dimension size (e.g. lon, lat dimensions).\n",
    "\n",
    "</div>\n",
    "\n",
    "Given files all named `ens_tas_m[member number].nc`, we use `glob` to get a list of all those files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import xclim as xc\n",
    "\n",
    "# Set display to HTML sytle (for fancy output)\n",
    "xr.set_options(display_style=\"html\", display_width=50)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from xclim import ensembles\n",
    "\n",
    "ens = ensembles.create_ensemble(glob.glob(\"ens_tas_m*.nc\")).load()\n",
    "ens.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-v0_8-dark\")\n",
    "plt.rcParams[\"figure.figsize\"] = (13, 5)\n",
    "ens.tas.plot(hue=\"realization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens.tas  # Attributes of the first dataset to be opened are copied to the final output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble statistics\n",
    "Beyond creating an ensemble dataset, the `xclim.ensembles` module contains functions for calculating statistics between realizations\n",
    "\n",
    "**Ensemble mean, standard-deviation, max & min**\n",
    "\n",
    "In the example below, we use xclim's `ensemble_mean_std_max_min()` to calculate statistics across the 10 realizations in our test dataset. Output variables are created combining the original variable name `tas` with additional ending indicating the statistic calculated on the realization dimension : `_mean`, `_stdev`, `_min`, `_max`\n",
    "\n",
    "The resulting output now contains 4 derived variables from the original single variable in our ensemble dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_stats = ensembles.ensemble_mean_std_max_min(ens)\n",
    "ens_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble percentiles\n",
    "\n",
    "Here, we use xclim's `ensemble_percentiles()` to calculate percentile values across the 10 realizations.\n",
    "The output has now a `percentiles` dimension instead of `realization`. Split variables can be created instead, by specifying `split=True` (the variable name `tas` will be appended with `_p{x}`). Compared to NumPy's `percentile()` and xarray's `quantile()`, this method handles more efficiently dataset with invalid values and the chunking along the realization dimension (which is automatic when dask arrays are used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_perc = ensembles.ensemble_percentiles(ens, values=[15, 50, 85], split=False)\n",
    "ens_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.fill_between(\n",
    "    ens_stats.time.values,\n",
    "    ens_stats.tas_min,\n",
    "    ens_stats.tas_max,\n",
    "    alpha=0.3,\n",
    "    label=\"Min-Max\",\n",
    ")\n",
    "ax.fill_between(\n",
    "    ens_perc.time.values,\n",
    "    ens_perc.tas.sel(percentiles=15),\n",
    "    ens_perc.tas.sel(percentiles=85),\n",
    "    alpha=0.5,\n",
    "    label=\"Perc. 15-85\",\n",
    ")\n",
    "ax._get_lines.get_next_color()  # Hack to get different line\n",
    "ax._get_lines.get_next_color()\n",
    "ax.plot(ens_stats.time.values, ens_stats.tas_mean, linewidth=2, label=\"Mean\")\n",
    "ax.plot(\n",
    "    ens_perc.time.values, ens_perc.tas.sel(percentiles=50), linewidth=2, label=\"Median\"\n",
    ")\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
